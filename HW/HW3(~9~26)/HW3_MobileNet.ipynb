{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4X9M25jzxef"
      },
      "source": [
        "# | HW3 | MobileNetV2 변형해 보기\n",
        "\n",
        "**Due: 9/26, 11:59 PM**\n",
        "\n",
        "- **채점 기준**\n",
        "  - 아래 과제 설명을 따라야한다.\n",
        "  - test accuracy가 **80% 이상** 나와야 한다.\n",
        "- **제출**\n",
        "  - \"HW3_학번_이름.ipynb\" 형태로 저장하여 Jupyter Notebook을 그대로 제출.\n",
        "    - 예: HW3_2022_12345_keondo.ipynb\n",
        "  - output 지우지 말아 주세요"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbiOlVdNzxei",
        "scrolled": false
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlwfSBH3zxej"
      },
      "source": [
        "`BatchNormalization(axis, momentum, epsilon)` : https://keras.io/api/layers/normalization_layers/batch_normalization/\n",
        "- axis: Batch normalization이 적용될 axis. 우리는 채널에 대해서 BN을 적용할 것이다. \n",
        "- momentum: Moving average에 적용될 momentum 계수\n",
        "- epsilon: 0으로 나누는 것을 방지하기 위한 작은 수.\n",
        "\n",
        "\n",
        "`DepthwiseConv2D(kernel_size, strides, padding, use_bias, depthwise_regularizer)` : https://keras.io/api/layers/convolution_layers/depthwise_convolution2d/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbeM7t9Wzxek"
      },
      "source": [
        "paper:[MobileNetV3](https://openaccess.thecvf.com/content_ICCV_2019/papers/Howard_Searching_for_MobileNetV3_ICCV_2019_paper.pdf)  \n",
        "\n",
        "이번 과제에서는 MobileNetV3에서 추가된 내용 중 일부를 반영해 볼 것이다. MobilenetV3에서는 모델의 마지막 부분에 아래 그림과 같은 변화가 있었는데, 요약하자면\n",
        "* Average pooling 앞의 1x1 Convolution layer와 Average pooling layer의 순서를 바꾸어 줌으로써 Computation은 줄이면서 정보의 손실은 최소화하였다.\n",
        "* 위 변화가 일어나게 됨으로써 그 이전 Inverted residual layer에서 projection/filtering을 해 줄 필요가 없어졌다. 따라서 마지막 Inverted residual layer의 Expansion 이후 바로 Average pooling이 오게 된다.\n",
        "* 아래 그림을 보면 더 이해가 쉬울 것이다.\n",
        "<img src=\"https://user-images.githubusercontent.com/37704174/112775642-734f8a80-9078-11eb-9bc1-a860a1fea407.PNG\" width=\"700\" height=\"700\"/> \n",
        "* 마지막 Inverted residual layer는 Original last stage 그림에서 맨 앞 세개이다.\n",
        "\n",
        "\n",
        "<br>\n",
        "위 내용을 참조하여 Network의 마지막 부분을 변형한 MobileNetV2plus를 구성하라. 위 그림상의 H-swish는 고려하지 않아도 된다.\n",
        "<img src=\"https://user-images.githubusercontent.com/37704174/112777027-1229b600-907c-11eb-9f89-a7b61c0843be.PNG\" width=\"700\" height=\"700\"/>  \n",
        "\n",
        "- **채점기준**\n",
        "  - 위의 변경 사항 반영하기\n",
        "    - MobileNetV2에서 마지막 inverted residual block 및 뒷부분을 고치면 됨\n",
        "    - Average pooling의 output의 가로 세로는 1임\n",
        "  - test accuracy **80%** 이상\n",
        "    - BatchNormalization, Activation, Dropout, Regularization, Weight initialization 등 자유롭게 수정, 추가, 제거 가능\n",
        "    - `strides` 수정 가능\n",
        "    - 나머지는 그대로\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zQAEuO1zxek"
      },
      "source": [
        "## Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PwJ-gqa8zxel",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "### Q1. Import modules ###\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Add, ReLU, Input, Dense, Activation, Flatten, Conv2D, \\\n",
        "    DepthwiseConv2D, BatchNormalization, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num_GPUs:1, List:[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\"\"\"\n",
        "Make sure your runtime type is GPU!\n",
        "\"\"\"\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "print('Num_GPUs:{}, List:{}'.format(len(physical_devices), physical_devices))\n",
        "gpu_growth = False\n",
        "\n",
        "if gpu_growth:\n",
        "    physical_devices = tf.config.list_physical_devices('GPU')\n",
        "    try:\n",
        "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "    except:\n",
        "        # Invalid device or cannot modify virtual devices once initialized.\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5-6x854zxem"
      },
      "source": [
        "## Inverted Residual Block\n",
        "\n",
        "- 실습 때 한 것과 동일 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KGjTG3kAzxem",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "def _inverted_res_block(inputs, expansion, filters, strides):\n",
        "    momentum = 0.999 # default: 0.99\n",
        "    regularization = 4e-5 # default : 4e-5\n",
        "\n",
        "    # momentum = 0.99 # default: 0.99\n",
        "    # regularization = 2e-5 # default : 4e-5\n",
        "    x = inputs\n",
        "    in_chnls = inputs.shape[-1]\n",
        "    # Expansion\n",
        "    if expansion != 1:\n",
        "        x = Conv2D(kernel_size=1, filters=in_chnls * expansion, strides=1, padding='same', use_bias=False, kernel_regularizer=l2(regularization))(x)\n",
        "        x = BatchNormalization(momentum=momentum, epsilon=0.001)(x)\n",
        "        x = ReLU(max_value=6)(x)\n",
        "        \n",
        "    # Depthwise convolution\n",
        "    x = DepthwiseConv2D(kernel_size=3, strides=strides, padding='same', use_bias=False, depthwise_regularizer=l2(regularization))(x)\n",
        "    x = BatchNormalization(momentum=momentum, epsilon=0.001)(x)\n",
        "    x = ReLU(max_value=6)(x)\n",
        "    \n",
        "    # Linear bottleneck\n",
        "    x = Conv2D(kernel_size=1, filters=filters, strides=1, padding='same', use_bias=False, kernel_regularizer=l2(regularization))(x)\n",
        "    x = BatchNormalization(momentum=momentum, epsilon=0.001)(x)\n",
        "    # No activation\n",
        "    \n",
        "    # Residual connection\n",
        "    if in_chnls == filters and strides == 1:\n",
        "        x = Add()([inputs, x])\n",
        "        \n",
        "    return x #return output of layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _inverted_res_block_Last(inputs, expansion, filters, strides):\n",
        "    # 마지막 inverted resudial layer의 expansion이후 바로 avergae pooling이 오게 됨\n",
        "\n",
        "    x = inputs\n",
        "    in_chnls = inputs.shape[-1]\n",
        "    \n",
        "    # Expansion\n",
        "    if expansion != 1:\n",
        "        x = Conv2D(kernel_size=1, filters=in_chnls * expansion, strides=1, padding='same', use_bias=False, kernel_regularizer=l2(4e-5))(x)\n",
        "        x = BatchNormalization(momentum=0.999, epsilon=0.001)(x)\n",
        "        x = ReLU(max_value=6)(x)\n",
        "\n",
        "    x = tf.keras.layers.AveragePooling2D(pool_size=1, padding=\"same\")(x)\n",
        "\n",
        "    ### need to be change the dimension to 1 x 1 from Batchsize, 960 -> Batchsize, 1, 1, 960\n",
        "    x = Conv2D(kernel_size=1, filters=1280, strides=1, padding='same')(x)\n",
        "\n",
        "    ### the result shape -> BatchSize, 1, 1, 1280\n",
        "    return x #return output of layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _inverted_res_block_Last(inputs, expansion, filters, strides):\n",
        "    # 마지막 inverted resudial layer의 expansion이후 바로 avergae pooling이 오게 됨\n",
        "\n",
        "    x = inputs\n",
        "    in_chnls = inputs.shape[-1]\n",
        "    \n",
        "    # Expansion\n",
        "    if expansion != 1:\n",
        "        x = Conv2D(kernel_size=1, filters=in_chnls * expansion, strides=1, padding='same', use_bias=False, kernel_regularizer=l2(4e-5))(x)\n",
        "        x = BatchNormalization(momentum=0.999, epsilon=0.001)(x)\n",
        "        x = ReLU(max_value=6)(x)\n",
        "\n",
        "    # x = tf.keras.layers.AveragePooling2D(pool_size=1, padding=\"same\")(x)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    print(x.shape)\n",
        "    org = x.shape\n",
        "    x = tf.reshape(x, org)\n",
        "    print(x.shape)\n",
        "\n",
        "    ### need to be change the dimension to 1 x 1 from Batchsize, 960 -> Batchsize, 1, 1, 960\n",
        "    x = Conv2D(kernel_size=1, filters=1280, strides=1, padding='same')(x)\n",
        "\n",
        "    ### the result shape -> BatchSize, 1, 1, 1280\n",
        "    return x #return output of layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBNLdmgTzxen"
      },
      "source": [
        "## MobileNetV2 변형 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "5TkdqcFRzxen",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "def MobileNetV2plus(input_shape, classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    initializers = tf.keras.initializers.HeNormal()\n",
        "\n",
        "    x = Conv2D(filters=32, kernel_size=3, strides=2, padding='same', kernel_initializer=initializers)(inputs)\n",
        "    x = BatchNormalization(momentum=0.999, epsilon=0.001)(x)\n",
        "    x = ReLU(max_value=6)(x)\n",
        "    \n",
        "    # inverted residual blocks\n",
        "    x = _inverted_res_block(inputs = x, expansion=1, filters=16, strides=1)\n",
        "\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=24, strides=2)\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=24, strides=1)\n",
        "    # x = Dropout(0.5)(x)\n",
        "\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=32, strides=2)\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=32, strides=1)\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=32, strides=1)\n",
        "\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=64, strides=2)\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=64, strides=1)\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=64, strides=1)\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=64, strides=1)\n",
        "    # x = Dropout(0.5)(x)\n",
        "\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=96, strides=1)\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=96, strides=1)\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=96, strides=1)\n",
        "    # x = Dropout(0.4)(x)\n",
        "    \n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=160, strides=2)\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=160, strides=1)\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=160, strides=1)\n",
        "    \n",
        "    # modified block\n",
        "    x = _inverted_res_block_Last(inputs = x, expansion=6, filters=160, strides=1)\n",
        "    \n",
        "    #3 FC layer\n",
        "    outputs = Dense(classes, activation='softmax')(x)\n",
        "    \n",
        "    return Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "1LvkStJhzxeo",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(None, 960)\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Failed to convert object of type <class 'list'> to Tensor. Contents: [None, 1, 1, 960]. Consider casting elements to a supported type.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[39mreturn\u001b[39;00m target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:195\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Reshapes a tensor.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \n\u001b[0;32m     64\u001b[0m \u001b[39mGiven `tensor`, this operation returns a new `tf.Tensor` that has the same\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[39m  A `Tensor`. Has the same type as `tensor`.\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 195\u001b[0m result \u001b[39m=\u001b[39m gen_array_ops\u001b[39m.\u001b[39;49mreshape(tensor, shape, name)\n\u001b[0;32m    196\u001b[0m tensor_util\u001b[39m.\u001b[39mmaybe_set_static_shape(result, shape)\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:8391\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m   8390\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 8391\u001b[0m   \u001b[39mreturn\u001b[39;00m reshape_eager_fallback(\n\u001b[0;32m   8392\u001b[0m       tensor, shape, name\u001b[39m=\u001b[39;49mname, ctx\u001b[39m=\u001b[39;49m_ctx)\n\u001b[0;32m   8393\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_SymbolicException:\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:8412\u001b[0m, in \u001b[0;36mreshape_eager_fallback\u001b[1;34m(tensor, shape, name, ctx)\u001b[0m\n\u001b[0;32m   8411\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape_eager_fallback\u001b[39m(tensor, shape, name, ctx):\n\u001b[1;32m-> 8412\u001b[0m   _attr_T, (tensor,) \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39;49margs_to_matching_eager([tensor], ctx, [])\n\u001b[0;32m   8413\u001b[0m   _attr_Tshape, (shape,) \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39margs_to_matching_eager([shape], ctx, [_dtypes\u001b[39m.\u001b[39mint32, _dtypes\u001b[39m.\u001b[39mint64, ], _dtypes\u001b[39m.\u001b[39mint32)\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:273\u001b[0m, in \u001b[0;36margs_to_matching_eager\u001b[1;34m(l, ctx, allowed_dtypes, default_dtype)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[39mif\u001b[39;00m tensor \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 273\u001b[0m   tensor \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(\n\u001b[0;32m    274\u001b[0m       t, dtype, preferred_dtype\u001b[39m=\u001b[39;49mdefault_dtype, ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    276\u001b[0m ret\u001b[39m.\u001b[39mappend(tensor)\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:163\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 163\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1566\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1565\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1566\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[0;32m   1568\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:339\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    338\u001b[0m _ \u001b[39m=\u001b[39m as_ref\n\u001b[1;32m--> 339\u001b[0m \u001b[39mreturn\u001b[39;00m constant(v, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname)\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:264\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \n\u001b[0;32m    170\u001b[0m \u001b[39mNote: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[39m  ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    265\u001b[0m                       allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:276\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    275\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 276\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m    278\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:301\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[39m\"\"\"Implementation of eager constant.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 301\u001b[0m t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[0;32m    302\u001b[0m \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:98\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     97\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 98\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\keras_tensor.py:254\u001b[0m, in \u001b[0;36mKerasTensor.__array__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 254\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    255\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mCannot convert a symbolic Keras input/output to a numpy array. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    256\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mThis error may indicate that you\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mre trying to pass a symbolic value \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    257\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mto a NumPy call, which is not supported. Or, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    258\u001b[0m       \u001b[39m'\u001b[39m\u001b[39myou may be trying to pass Keras symbolic inputs/outputs \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    259\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mto a TF API that does not register dispatching, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    260\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mpreventing Keras from automatically \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    261\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mconverting the API call to a lambda layer \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    262\u001b[0m       \u001b[39m'\u001b[39m\u001b[39min the Functional Model.\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[1;31mTypeError\u001b[0m: Cannot convert a symbolic Keras input/output to a numpy array. This error may indicate that you're trying to pass a symbolic value to a NumPy call, which is not supported. Or, you may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:549\u001b[0m, in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 549\u001b[0m   str_values \u001b[39m=\u001b[39m [compat\u001b[39m.\u001b[39mas_bytes(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m proto_values]\n\u001b[0;32m    550\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:549\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 549\u001b[0m   str_values \u001b[39m=\u001b[39m [compat\u001b[39m.\u001b[39;49mas_bytes(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m proto_values]\n\u001b[0;32m    550\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\util\\compat.py:86\u001b[0m, in \u001b[0;36mas_bytes\u001b[1;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mExpected binary or unicode string, got \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m     87\u001b[0m                   (bytes_or_text,))\n",
            "\u001b[1;31mTypeError\u001b[0m: Expected binary or unicode string, got None",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m my_mobilenet \u001b[38;5;241m=\u001b[39m \u001b[43mMobileNetV2plus\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn [28], line 37\u001b[0m, in \u001b[0;36mMobileNetV2plus\u001b[1;34m(input_shape, classes)\u001b[0m\n\u001b[0;32m     34\u001b[0m x \u001b[38;5;241m=\u001b[39m _inverted_res_block(inputs \u001b[38;5;241m=\u001b[39m x, expansion\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m160\u001b[39m, strides\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# modified block\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43m_inverted_res_block_Last\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpansion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m160\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m#3 FC layer\u001b[39;00m\n\u001b[0;32m     40\u001b[0m outputs \u001b[38;5;241m=\u001b[39m Dense(classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n",
            "Cell \u001b[1;32mIn [27], line 16\u001b[0m, in \u001b[0;36m_inverted_res_block_Last\u001b[1;34m(inputs, expansion, filters, strides)\u001b[0m\n\u001b[0;32m     14\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mGlobalAveragePooling2D()(x)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 16\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m960\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m### need to be change the dimension to 1 x 1 from Batchsize, 960 -> Batchsize, 1, 1, 960\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:210\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    206\u001b[0m   \u001b[39mreturn\u001b[39;00m target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m   result \u001b[39m=\u001b[39m dispatch(wrapper, args, kwargs)\n\u001b[0;32m    211\u001b[0m   \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m OpDispatcher\u001b[39m.\u001b[39mNOT_SUPPORTED:\n\u001b[0;32m    212\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:126\u001b[0m, in \u001b[0;36mdispatch\u001b[1;34m(op, args, kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m    125\u001b[0m \u001b[39mfor\u001b[39;00m dispatcher \u001b[39min\u001b[39;00m _GLOBAL_DISPATCHERS:\n\u001b[1;32m--> 126\u001b[0m   result \u001b[39m=\u001b[39m dispatcher\u001b[39m.\u001b[39;49mhandle(op, args, kwargs)\n\u001b[0;32m    127\u001b[0m   \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m OpDispatcher\u001b[39m.\u001b[39mNOT_SUPPORTED:\n\u001b[0;32m    128\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:1486\u001b[0m, in \u001b[0;36mKerasOpDispatcher.handle\u001b[1;34m(self, op, args, kwargs)\u001b[0m\n\u001b[0;32m   1482\u001b[0m \u001b[39m\"\"\"Handle the specified operation with the specified arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m   1483\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\n\u001b[0;32m   1484\u001b[0m     \u001b[39misinstance\u001b[39m(x, keras_tensor\u001b[39m.\u001b[39mKerasTensor)\n\u001b[0;32m   1485\u001b[0m     \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m nest\u001b[39m.\u001b[39mflatten([args, kwargs])):\n\u001b[1;32m-> 1486\u001b[0m   \u001b[39mreturn\u001b[39;00m TFOpLambda(op)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1487\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1488\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mNOT_SUPPORTED\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:969\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[39m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[0;32m    964\u001b[0m \u001b[39m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[0;32m    965\u001b[0m \u001b[39m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[0;32m    966\u001b[0m \u001b[39m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[39m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[0;32m    968\u001b[0m \u001b[39mif\u001b[39;00m _in_functional_construction_mode(\u001b[39mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[1;32m--> 969\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m    970\u001b[0m                                             input_list)\n\u001b[0;32m    972\u001b[0m \u001b[39m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[0;32m    973\u001b[0m call_context \u001b[39m=\u001b[39m base_layer_utils\u001b[39m.\u001b[39mcall_context()\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1107\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     training_arg_passed_by_framework \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1104\u001b[0m \u001b[39mwith\u001b[39;00m call_context\u001b[39m.\u001b[39menter(\n\u001b[0;32m   1105\u001b[0m     layer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, inputs\u001b[39m=\u001b[39minputs, build_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39mtraining_value):\n\u001b[0;32m   1106\u001b[0m   \u001b[39m# Check input assumptions set after layer building, e.g. input shape.\u001b[39;00m\n\u001b[1;32m-> 1107\u001b[0m   outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_keras_tensor_symbolic_call(\n\u001b[0;32m   1108\u001b[0m       inputs, input_masks, args, kwargs)\n\u001b[0;32m   1110\u001b[0m   \u001b[39mif\u001b[39;00m outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1111\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mA layer\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39ms `call` method should return a \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1112\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mTensor or a list of Tensors, not None \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1113\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39m(layer: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m).\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:840\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    838\u001b[0m   \u001b[39mreturn\u001b[39;00m nest\u001b[39m.\u001b[39mmap_structure(keras_tensor\u001b[39m.\u001b[39mKerasTensor, output_signature)\n\u001b[0;32m    839\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 840\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_infer_output_signature(inputs, args, kwargs, input_masks)\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:880\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    878\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_build(inputs)\n\u001b[0;32m    879\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[1;32m--> 880\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    882\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[0;32m    883\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_mask_metadata(inputs, outputs, input_masks,\n\u001b[0;32m    884\u001b[0m                         build_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:1363\u001b[0m, in \u001b[0;36mTFOpLambda.__init__.<locals>._call_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_wrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 1363\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_wrapper(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:1395\u001b[0m, in \u001b[0;36mTFOpLambda._call_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1388\u001b[0m \u001b[39mwith\u001b[39;00m backprop\u001b[39m.\u001b[39mGradientTape(watch_accessed_variables\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m tape, \\\n\u001b[0;32m   1389\u001b[0m     variable_scope\u001b[39m.\u001b[39mvariable_creator_scope(_variable_creator):\n\u001b[0;32m   1390\u001b[0m   \u001b[39m# We explicitly drop `name` arguments here,\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m   \u001b[39m# to guard against the case where an op explicitly has a\u001b[39;00m\n\u001b[0;32m   1392\u001b[0m   \u001b[39m# `name` passed (which is susceptible to producing\u001b[39;00m\n\u001b[0;32m   1393\u001b[0m   \u001b[39m# multiple ops w/ the same name when the layer is reused)\u001b[39;00m\n\u001b[0;32m   1394\u001b[0m   kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 1395\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1396\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_variables(created_variables, tape\u001b[39m.\u001b[39mwatched_variables())\n\u001b[0;32m   1397\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[39mreturn\u001b[39;00m target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[39m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:195\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmanip.reshape\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     60\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m     61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape\u001b[39m(tensor, shape, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):  \u001b[39m# pylint: disable=redefined-outer-name\u001b[39;00m\n\u001b[0;32m     62\u001b[0m   \u001b[39mr\u001b[39m\u001b[39m\"\"\"Reshapes a tensor.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \n\u001b[0;32m     64\u001b[0m \u001b[39m  Given `tensor`, this operation returns a new `tf.Tensor` that has the same\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[39m    A `Tensor`. Has the same type as `tensor`.\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 195\u001b[0m   result \u001b[39m=\u001b[39m gen_array_ops\u001b[39m.\u001b[39;49mreshape(tensor, shape, name)\n\u001b[0;32m    196\u001b[0m   tensor_util\u001b[39m.\u001b[39mmaybe_set_static_shape(result, shape)\n\u001b[0;32m    197\u001b[0m   \u001b[39mreturn\u001b[39;00m result\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:8396\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m   8394\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m   8395\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m-> 8396\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m   8397\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mReshape\u001b[39;49m\u001b[39m\"\u001b[39;49m, tensor\u001b[39m=\u001b[39;49mtensor, shape\u001b[39m=\u001b[39;49mshape, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   8398\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m   8399\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:525\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    524\u001b[0m   \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 525\u001b[0m     \u001b[39mraise\u001b[39;00m err\n\u001b[0;32m    526\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    527\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    528\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExpected \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m passed to parameter \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m of op \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, got \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    529\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtype \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m instead. Error: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m    530\u001b[0m         (dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mname, input_arg\u001b[39m.\u001b[39mname, op_type_name,\n\u001b[0;32m    531\u001b[0m          \u001b[39mrepr\u001b[39m(values), \u001b[39mtype\u001b[39m(values)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, err))\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:511\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    509\u001b[0m     values \u001b[39m=\u001b[39m inferred\n\u001b[0;32m    510\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 511\u001b[0m     values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(\n\u001b[0;32m    512\u001b[0m         values,\n\u001b[0;32m    513\u001b[0m         name\u001b[39m=\u001b[39;49minput_arg\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    514\u001b[0m         as_ref\u001b[39m=\u001b[39;49minput_arg\u001b[39m.\u001b[39;49mis_ref,\n\u001b[0;32m    515\u001b[0m         preferred_dtype\u001b[39m=\u001b[39;49mdefault_dtype)\n\u001b[0;32m    516\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    517\u001b[0m   values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(\n\u001b[0;32m    518\u001b[0m       values,\n\u001b[0;32m    519\u001b[0m       name\u001b[39m=\u001b[39minput_arg\u001b[39m.\u001b[39mname,\n\u001b[0;32m    520\u001b[0m       dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m    521\u001b[0m       as_ref\u001b[39m=\u001b[39minput_arg\u001b[39m.\u001b[39mis_ref,\n\u001b[0;32m    522\u001b[0m       preferred_dtype\u001b[39m=\u001b[39mdefault_dtype)\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:163\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    162\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 163\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1566\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1561\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mconvert_to_tensor did not convert to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1562\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mthe preferred dtype: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m vs \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1563\u001b[0m                       (ret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype, preferred_dtype\u001b[39m.\u001b[39mbase_dtype))\n\u001b[0;32m   1565\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1566\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[0;32m   1568\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[0;32m   1569\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:339\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    337\u001b[0m                                          as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    338\u001b[0m   _ \u001b[39m=\u001b[39m as_ref\n\u001b[1;32m--> 339\u001b[0m   \u001b[39mreturn\u001b[39;00m constant(v, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname)\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:264\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    168\u001b[0m   \u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \n\u001b[0;32m    170\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    265\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:281\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    278\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[0;32m    279\u001b[0m tensor_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue()\n\u001b[0;32m    280\u001b[0m tensor_value\u001b[39m.\u001b[39mtensor\u001b[39m.\u001b[39mCopyFrom(\n\u001b[1;32m--> 281\u001b[0m     tensor_util\u001b[39m.\u001b[39;49mmake_tensor_proto(\n\u001b[0;32m    282\u001b[0m         value, dtype\u001b[39m=\u001b[39;49mdtype, shape\u001b[39m=\u001b[39;49mshape, verify_shape\u001b[39m=\u001b[39;49mverify_shape,\n\u001b[0;32m    283\u001b[0m         allow_broadcast\u001b[39m=\u001b[39;49mallow_broadcast))\n\u001b[0;32m    284\u001b[0m dtype_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue(\u001b[39mtype\u001b[39m\u001b[39m=\u001b[39mtensor_value\u001b[39m.\u001b[39mtensor\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m    285\u001b[0m attrs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m: tensor_value, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m: dtype_value}\n",
            "File \u001b[1;32mc:\\Users\\gkstk\\miniconda3\\envs\\tf_250\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:551\u001b[0m, in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    549\u001b[0m   str_values \u001b[39m=\u001b[39m [compat\u001b[39m.\u001b[39mas_bytes(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m proto_values]\n\u001b[0;32m    550\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m--> 551\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mFailed to convert object of type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m to Tensor. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    552\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39mContents: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m. Consider casting elements to a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    553\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39msupported type.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mtype\u001b[39m(values), values))\n\u001b[0;32m    554\u001b[0m tensor_proto\u001b[39m.\u001b[39mstring_val\u001b[39m.\u001b[39mextend(str_values)\n\u001b[0;32m    555\u001b[0m \u001b[39mreturn\u001b[39;00m tensor_proto\n",
            "\u001b[1;31mTypeError\u001b[0m: Failed to convert object of type <class 'list'> to Tensor. Contents: [None, 1, 1, 960]. Consider casting elements to a supported type."
          ]
        }
      ],
      "source": [
        "my_mobilenet = MobileNetV2plus((32,32,3),classes=10)\n",
        "# my_mobilenet.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O69GTfOTzxeo"
      },
      "source": [
        "## Training Data\n",
        "\n",
        "- keras dataset 혹은 tensorflow dataset 이용\n",
        "- train data를 9:1로 나눠서 validation data로 이용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azOxenuyzxep",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "#Load data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#Split train set into train/valid set\n",
        "from sklearn import model_selection\n",
        "x_train, x_valid, y_train, y_valid = model_selection.train_test_split(x_train, y_train,test_size=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1R87-fgzxep"
      },
      "source": [
        "## Data Preprocessing\n",
        "자유롭게 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYETZHz1zxep",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "### Q3. Preporcessing ###\n",
        "\n",
        "x_train, x_valid, x_test = x_train / 255.0, x_valid / 255.0, x_test / 255.0\n",
        "\n",
        "# # --------------------------------------------------------------------------------\n",
        "\n",
        "# #Data preprocessing/augmentation for training images\n",
        "# import numpy as np\n",
        "# print (\"mean before normalization:\", np.mean(x_train)) \n",
        "# print (\"std before normalization:\", np.std(x_train))\n",
        "# print(\"\\n\")\n",
        "\n",
        "# mean=[0,0,0]\n",
        "# std=[0,0,0]\n",
        "\n",
        "# newX_train = np.ones(x_train.shape)\n",
        "# newX_valid = np.ones(x_valid.shape)\n",
        "# newX_test = np.ones(x_test.shape)\n",
        "\n",
        "# #train, valid, test set에 있는 데이터로 평균과 표준편차를 구함\n",
        "# trainList = [x_train, x_valid, x_test]\n",
        "# for i in range(3):\n",
        "#     mean[i] = np.mean(trainList[i][:,:,:,i])\n",
        "#     std[i] = np.std(trainList[i][:,:,:,i])\n",
        "\n",
        "# #train과 test셋 모두 정규화 작업    \n",
        "# for i in range(3):\n",
        "#     newX_train[:,:,:,i] = x_train[:,:,:,i] - mean[i]\n",
        "#     newX_train[:,:,:,i] = newX_train[:,:,:,i] / std[i]\n",
        "\n",
        "#     newX_valid[:,:,:,i] = x_valid[:,:,:,i] - mean[i]\n",
        "#     newX_valid[:,:,:,i] = newX_valid[:,:,:,i] / std[i]\n",
        "\n",
        "#     newX_test[:,:,:,i] = x_test[:,:,:,i] - mean[i]\n",
        "#     newX_test[:,:,:,i] = newX_test[:,:,:,i] / std[i]\n",
        "        \n",
        "# x_train = newX_train\n",
        "# x_valid = newX_valid\n",
        "# x_test = newX_test\n",
        "# trainList = [x_train, x_valid, x_test]\n",
        "\n",
        "# for dataSet in trainList:\n",
        "#     print(dataSet.shape)\n",
        "#     print (\"mean after normalization:\", np.mean(dataSet))\n",
        "#     print (\"std after normalization:\", np.std(dataSet))\n",
        "#     print(dataSet.max())\n",
        "\n",
        "# # --------------------------------------------------------------------------------\n",
        "\n",
        "# ### set up image augmentation\n",
        "# from keras.preprocessing.image import ImageDataGenerator\n",
        "# datagen = ImageDataGenerator(\n",
        "#     rotation_range=15,\n",
        "#     horizontal_flip=True,\n",
        "#     width_shift_range=0.1,\n",
        "#     height_shift_range=0.1\n",
        "#     )\n",
        "    \n",
        "# datagen.fit(x_train)\n",
        "# datagen.fit(x_valid)\n",
        "# datagen.fit(x_test)\n",
        "\n",
        "# # --------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6BOLhxLzxep"
      },
      "source": [
        "## Model Compile\n",
        "loss function, optimizer 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Learning rate decay function\n",
        "def decay(epoch):\n",
        "    ####### 실습 #######\n",
        "    if epoch < 10:\n",
        "        return 1e-3\n",
        "    elif epoch < 30:\n",
        "        return 1e-4\n",
        "    else:\n",
        "        return 1e-5\n",
        "    ###################\n",
        "    \n",
        "import math\n",
        "def exp_decay(epoch):\n",
        "    ####### 실습 #######\n",
        "    if epoch < 10:\n",
        "        return 0.01\n",
        "    else:\n",
        "        return 0.01 * math.exp(0.5 * (10-epoch))\n",
        "    ###################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kti2fkFzxep",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "### Q4. Model compile ###\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "my_mobilenet.compile(loss=loss_fn, optimizer='adam', metrics=['accuracy'])\n",
        "#########################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSOCZ5ctzxeq",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "### Q5. Callbacks ###\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.LearningRateScheduler(exp_decay), \n",
        "    tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=5),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=7)\n",
        "]\n",
        "#####################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2w6KyPvzxeq"
      },
      "source": [
        "## Model Training\n",
        "hyperparameter를 적절히 설정한다. (epochs 등..)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nOCP5xxzxeq",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "### Q6. Training ###\n",
        "history = my_mobilenet.fit(x_train, y_train, batch_size= 32, \n",
        "                          epochs= 30,\n",
        "                          callbacks=callbacks,              \n",
        "                          validation_data=(x_valid, y_valid),\n",
        "                          shuffle=True)\n",
        "####################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WzvdkTkzxeq"
      },
      "source": [
        "## 참고용\n",
        "조교가 학습한 모델의 validation accuracy를 그래프로 나타내 보았다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcd2exS-zxeq",
        "outputId": "9dc6b7ab-535f-40ee-f643-4ea62206c140",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Validation Accuracy', fontsize=15)\n",
        "plt.xlabel('epochs', fontsize=15)\n",
        "plt.ylabel('Acc.', fontsize=15)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLf12NSyzxer"
      },
      "source": [
        "## Test Accuracy\n",
        "\n",
        "test accuracy 측정 결과 **80% 이상**이 나와야 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TZdoqT9zxer",
        "outputId": "adb52b13-eb10-40a1-9fb4-787d5b0f50fd",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "my_mobilenet.evaluate(x_test,y_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "HW3_MobileNet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.11 ('tf_250')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "6ef1ab2cc6bb34a12f51e5a9ebf3e384b0f3eb94e651016afecac1fc3101c448"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
