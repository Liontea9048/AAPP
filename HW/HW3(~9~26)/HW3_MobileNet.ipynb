{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4X9M25jzxef"
      },
      "source": [
        "# | HW3 | MobileNetV2 변형해 보기\n",
        "\n",
        "**Due: 9/26, 11:59 PM**\n",
        "\n",
        "- **채점 기준**\n",
        "  - 아래 과제 설명을 따라야한다.\n",
        "  - test accuracy가 **80% 이상** 나와야 한다.\n",
        "- **제출**\n",
        "  - \"HW3_학번_이름.ipynb\" 형태로 저장하여 Jupyter Notebook을 그대로 제출.\n",
        "    - 예: HW3_2022_12345_keondo.ipynb\n",
        "  - output 지우지 말아 주세요"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbiOlVdNzxei",
        "scrolled": false
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlwfSBH3zxej"
      },
      "source": [
        "`BatchNormalization(axis, momentum, epsilon)` : https://keras.io/api/layers/normalization_layers/batch_normalization/\n",
        "- axis: Batch normalization이 적용될 axis. 우리는 채널에 대해서 BN을 적용할 것이다. \n",
        "- momentum: Moving average에 적용될 momentum 계수\n",
        "- epsilon: 0으로 나누는 것을 방지하기 위한 작은 수.\n",
        "\n",
        "\n",
        "`DepthwiseConv2D(kernel_size, strides, padding, use_bias, depthwise_regularizer)` : https://keras.io/api/layers/convolution_layers/depthwise_convolution2d/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbeM7t9Wzxek"
      },
      "source": [
        "paper:[MobileNetV3](https://openaccess.thecvf.com/content_ICCV_2019/papers/Howard_Searching_for_MobileNetV3_ICCV_2019_paper.pdf)  \n",
        "\n",
        "이번 과제에서는 MobileNetV3에서 추가된 내용 중 일부를 반영해 볼 것이다. MobilenetV3에서는 모델의 마지막 부분에 아래 그림과 같은 변화가 있었는데, 요약하자면\n",
        "* Average pooling 앞의 1x1 Convolution layer와 Average pooling layer의 순서를 바꾸어 줌으로써 Computation은 줄이면서 정보의 손실은 최소화하였다.\n",
        "* 위 변화가 일어나게 됨으로써 그 이전 Inverted residual layer에서 projection/filtering을 해 줄 필요가 없어졌다. 따라서 마지막 Inverted residual layer의 Expansion 이후 바로 Average pooling이 오게 된다.\n",
        "* 아래 그림을 보면 더 이해가 쉬울 것이다.\n",
        "<img src=\"https://user-images.githubusercontent.com/37704174/112775642-734f8a80-9078-11eb-9bc1-a860a1fea407.PNG\" width=\"700\" height=\"700\"/> \n",
        "* 마지막 Inverted residual layer는 Original last stage 그림에서 맨 앞 세개이다.\n",
        "\n",
        "\n",
        "<br>\n",
        "위 내용을 참조하여 Network의 마지막 부분을 변형한 MobileNetV2plus를 구성하라. 위 그림상의 H-swish는 고려하지 않아도 된다.\n",
        "<img src=\"https://user-images.githubusercontent.com/37704174/112777027-1229b600-907c-11eb-9f89-a7b61c0843be.PNG\" width=\"700\" height=\"700\"/>  \n",
        "\n",
        "- **채점기준**\n",
        "  - 위의 변경 사항 반영하기\n",
        "    - MobileNetV2에서 마지막 inverted residual block 및 뒷부분을 고치면 됨\n",
        "    - Average pooling의 output의 가로 세로는 1임\n",
        "  - test accuracy **80%** 이상\n",
        "    - BatchNormalization, Activation, Dropout, Regularization, Weight initialization 등 자유롭게 수정, 추가, 제거 가능\n",
        "    - `strides` 수정 가능\n",
        "    - 나머지는 그대로\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zQAEuO1zxek"
      },
      "source": [
        "## Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PwJ-gqa8zxel",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/liontea/miniconda3/envs/tf2.9.2_p3.10.5/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "### Q1. Import modules ###\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Add, ReLU, Input, Dense, Activation, Flatten, Conv2D, \\\n",
        "    DepthwiseConv2D, BatchNormalization, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5-6x854zxem"
      },
      "source": [
        "## Inverted Residual Block\n",
        "\n",
        "- 실습 때 한 것과 동일 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KGjTG3kAzxem",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "def _inverted_res_block(inputs, expansion, filters, strides):\n",
        "    x = inputs\n",
        "    in_chnls = inputs.shape[-1]\n",
        "    # Expansion\n",
        "    if expansion != 1:\n",
        "        x = Conv2D(kernel_size=1, filters=in_chnls * expansion, strides=1, padding='same', use_bias=False, kernel_regularizer=l2(4e-5))(x)\n",
        "        x = BatchNormalization(momentum=0.999, epsilon=0.001)(x)\n",
        "        x = ReLU(max_value=6)(x)\n",
        "        \n",
        "    # Depthwise convolution\n",
        "    x = DepthwiseConv2D(kernel_size=3, strides=strides, padding='same', use_bias=False, depthwise_regularizer=l2(4e-5))(x)\n",
        "    x = BatchNormalization(momentum=0.999, epsilon=0.001)(x)\n",
        "    x = ReLU(max_value=6)(x)\n",
        "    \n",
        "    # Linear bottleneck\n",
        "    x = Conv2D(kernel_size=1, filters=filters, strides=1, padding='same', use_bias=False, kernel_regularizer=l2(4e-5))(x)\n",
        "    x = BatchNormalization(momentum=0.999, epsilon=0.001)(x)\n",
        "    # No activation\n",
        "    \n",
        "    # Residual connection\n",
        "    if in_chnls == filters and strides == 1:\n",
        "        x = Add()([inputs, x])\n",
        "        \n",
        "    return x #return output of layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _inverted_res_block_Efficient(inputs, expansion, filters, strides):\n",
        "    # 마지막 inverted resudial layer의 expansion이후 바로 avergae pooling이 오게 됨\n",
        "    # -> Depthwise conv와 concat필요 없음\n",
        "    x = inputs\n",
        "    in_chnls = inputs.shape[-1]\n",
        "    \n",
        "    # Expansion\n",
        "    if expansion != 1:\n",
        "        x = Conv2D(kernel_size=1, filters=in_chnls * expansion, strides=1, padding='same', use_bias=False, kernel_regularizer=l2(4e-5))(x)\n",
        "        x = BatchNormalization(momentum=0.999, epsilon=0.001)(x)\n",
        "        x = ReLU(max_value=6)(x)\n",
        "        \n",
        "    return x #return output of layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num_GPUs:1, List:[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\"\"\"\n",
        "Make sure your runtime type is GPU!\n",
        "\"\"\"\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "print('Num_GPUs:{}, List:{}'.format(len(physical_devices), physical_devices))\n",
        "gpu_growth = False\n",
        "\n",
        "if gpu_growth:\n",
        "    physical_devices = tf.config.list_physical_devices('GPU')\n",
        "    try:\n",
        "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "    except:\n",
        "        # Invalid device or cannot modify virtual devices once initialized.\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBNLdmgTzxen"
      },
      "source": [
        "## MobileNetV2 변형 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "5TkdqcFRzxen",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "def MobileNetV2plus(input_shape, classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(filters=32, kernel_size=3, strides=2, padding='same')(inputs)\n",
        "    x = BatchNormalization(momentum=0.999, epsilon=0.001)(x)\n",
        "    x = ReLU(max_value=6)(x)\n",
        "    \n",
        "    # inverted residual blocks\n",
        "    x = _inverted_res_block(inputs = x, expansion=1, filters=16, strides=1)\n",
        "\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=24, strides=2)\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=24, strides=1)\n",
        "    x = Dropout(0.5)\n",
        "\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=32, strides=2)\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=32, strides=1)\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=32, strides=1)\n",
        "    x = Dropout(0.5)\n",
        "\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=64, strides=2)\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=64, strides=1)\n",
        "    x = Dropout(0.5)\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=64, strides=1)\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=64, strides=1)\n",
        "\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=96, strides=1)\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=96, strides=1)\n",
        "    x = Dropout(0.5)\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=96, strides=1)\n",
        "\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=160, strides=2)\n",
        "    x = _inverted_res_block(inputs = x, expansion=6, filters=160, strides=1)\n",
        "    x = _inverted_res_block_Efficient(inputs = x, expansion=6, filters=160, strides=1)\n",
        "\n",
        "    ######################################################### - where we modifiy\n",
        "    \n",
        "    #1 global average pooling\n",
        "    x = GlobalAveragePooling2D(keepdims=True)(x)\n",
        "    \n",
        "    #2 1x1Conv BN ReLU\n",
        "    x = Conv2D(kernel_size=1, filters=1280, strides=1, padding='same')(x)\n",
        "    x = BatchNormalization(momentum=0.999, epsilon=0.001)(x)\n",
        "    x = ReLU(max_value=6)(x)\n",
        "    \n",
        "    #3 FC layer\n",
        "    outputs = Dense(classes, activation='softmax')(x)\n",
        "    \n",
        "    return Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "1LvkStJhzxeo",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "my_mobilenet = MobileNetV2plus((32,32,3),classes=10)\n",
        "# my_mobilenet.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O69GTfOTzxeo"
      },
      "source": [
        "## Training Data\n",
        "\n",
        "- keras dataset 혹은 tensorflow dataset 이용\n",
        "- train data를 9:1로 나눠서 validation data로 이용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "azOxenuyzxep",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "#Load data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#Split train set into train/valid set\n",
        "from sklearn import model_selection\n",
        "x_train, x_valid, y_train, y_valid = model_selection.train_test_split(x_train, y_train,test_size=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1R87-fgzxep"
      },
      "source": [
        "## Data Preprocessing\n",
        "자유롭게 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ZYETZHz1zxep",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean before normalization: 120.73160056423612\n",
            "std before normalization: 64.1701416551686\n",
            "mean after normalization: -3.0270436363261307e-17\n",
            "std after normalization: 0.999999999999997\n",
            "2.125997496782931\n"
          ]
        }
      ],
      "source": [
        "### Q3. Preporcessing ###\n",
        "#Data preprocessing/augmentation for training images\n",
        "import numpy as np\n",
        "print (\"mean before normalization:\", np.mean(x_train)) \n",
        "print (\"std before normalization:\", np.std(x_train))\n",
        "\n",
        "mean=[0,0,0]\n",
        "std=[0,0,0]\n",
        "newX_train = np.ones(x_train.shape)\n",
        "newX_valid = np.ones(x_valid.shape)\n",
        "newX_test = np.ones(x_test.shape)\n",
        "#train set에 있는 데이터로만 평균과 표준편차를 구함\n",
        "for i in range(3):\n",
        "    mean[i] = np.mean(x_train[:,:,:,i])\n",
        "    std[i] = np.std(x_train[:,:,:,i])\n",
        "\n",
        "#train과 test셋 모두 정규화 작업    \n",
        "for i in range(3):\n",
        "    newX_train[:,:,:,i] = x_train[:,:,:,i] - mean[i]\n",
        "    newX_train[:,:,:,i] = newX_train[:,:,:,i] / std[i]\n",
        "    newX_valid[:,:,:,i] = x_valid[:,:,:,i] - mean[i]\n",
        "    newX_valid[:,:,:,i] = newX_valid[:,:,:,i] / std[i]\n",
        "    newX_test[:,:,:,i] = x_test[:,:,:,i] - mean[i]\n",
        "    newX_test[:,:,:,i] = newX_test[:,:,:,i] / std[i]\n",
        "        \n",
        "x_train = newX_train\n",
        "x_valid = newX_valid\n",
        "x_test = newX_test\n",
        "\n",
        "print (\"mean after normalization:\", np.mean(x_train))\n",
        "print (\"std after normalization:\", np.std(x_train))\n",
        "print(x_train.max())\n",
        "\n",
        "# ---\n",
        "# set up image augmentation\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=35,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        "    )\n",
        "    \n",
        "datagen.fit(x_train)\n",
        "datagen.fit(x_valid)\n",
        "datagen.fit(x_test)\n",
        "#########################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6BOLhxLzxep"
      },
      "source": [
        "## Model Compile\n",
        "loss function, optimizer 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Learning rate decay function\n",
        "def decay(epoch):\n",
        "    ####### 실습 #######\n",
        "    if epoch < 10:\n",
        "        return 1e-3\n",
        "    elif epoch < 30:\n",
        "        return 1e-4\n",
        "    else:\n",
        "        return 1e-5\n",
        "    ###################\n",
        "    \n",
        "import math\n",
        "def exp_decay(epoch):\n",
        "    ####### 실습 #######\n",
        "    if epoch < 10:\n",
        "        return 0.001\n",
        "    else:\n",
        "        return 0.001 * math.exp(0.5 * (10-epoch))\n",
        "    ###################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "5kti2fkFzxep",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "### Q4. Model compile ###\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "my_mobilenet.compile(loss=loss_fn, optimizer='adam', metrics=['accuracy'])\n",
        "#########################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "DSOCZ5ctzxeq",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "### Q5. Callbacks ###\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.LearningRateScheduler(exp_decay), \n",
        "    tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=5),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=7)\n",
        "]\n",
        "#####################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2w6KyPvzxeq"
      },
      "source": [
        "## Model Training\n",
        "hyperparameter를 적절히 설정한다. (epochs 등..)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "3nOCP5xxzxeq",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-09-24 12:47:34.201896: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
            "2022-09-24 12:47:36.348211: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "704/704 [==============================] - ETA: 0s - loss: 2.0289 - accuracy: 0.1010"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-09-24 12:48:26.705093: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "704/704 [==============================] - 55s 61ms/step - loss: 2.0289 - accuracy: 0.1010 - val_loss: 2.4837 - val_accuracy: 0.1078 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "704/704 [==============================] - 40s 56ms/step - loss: 1.7311 - accuracy: 0.1014 - val_loss: 2.5252 - val_accuracy: 0.1020 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "549/704 [======================>.......] - ETA: 8s - loss: 1.5264 - accuracy: 0.1026"
          ]
        }
      ],
      "source": [
        "### Q6. Training ###\n",
        "history = my_mobilenet.fit(x_train, y_train, batch_size= 64, \n",
        "                          epochs= 10,\n",
        "                          callbacks=callbacks,              \n",
        "                          validation_data=(x_valid, y_valid))\n",
        "####################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WzvdkTkzxeq"
      },
      "source": [
        "## 참고용\n",
        "조교가 학습한 모델의 validation accuracy를 그래프로 나타내 보았다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcd2exS-zxeq",
        "outputId": "9dc6b7ab-535f-40ee-f643-4ea62206c140",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Validation Accuracy', fontsize=15)\n",
        "plt.xlabel('epochs', fontsize=15)\n",
        "plt.ylabel('Acc.', fontsize=15)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLf12NSyzxer"
      },
      "source": [
        "## Test Accuracy\n",
        "\n",
        "test accuracy 측정 결과 **80% 이상**이 나와야 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TZdoqT9zxer",
        "outputId": "adb52b13-eb10-40a1-9fb4-787d5b0f50fd",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "my_mobilenet.evaluate(x_test,y_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "HW3_MobileNet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('tf2.9.2_p3.10.5')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "8c31b0689a7bec413e878940c4f2ea1fe706742fa9eff333423f2bce8cde687e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
